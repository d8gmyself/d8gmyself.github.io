<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hystrix简单监控]]></title>
    <url>%2F2018%2F10%2F12%2FHystrix%E7%AE%80%E5%8D%95%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[前段时间产品找到我，想知道线上某个使用Hystrix的接口的熔断率是多少，因为经常有客服反馈问题，然后…我只能乖乖去扒日志，有日志的还好，如果没有明确日志… 所以，当时就在想，有没有类似的监控可以用，可以一目了然的知道各个系统中Hystrix运行的各项数值，比如访问了多少次，成功多少次，fallback了多少次，fallback成功多少次，失败多少次等等。 通过查阅资料，发现了hystrix-metrics-event-stream组件，就是官方自带的用来获取运行数据的组件，同时可以配套一起用的还有一个dashboard，可以用来获取实时运行情况，本地搭建了一个小demo后，发现这个dashboard并不是我想要的，我这边的述求就是想简单的了解一下，程序开始运行到现在Hystrix的整体运行情况。所以，简单看了一下hystrix-metrics-event-stream，发现其实想要实现我期望的功能，很简单，思路如下： 一、简易监控通过日志的形式，来查看服务启动以来hystrix的运行状况，配置方式如下： 1、配置监控（HystrixMetricsPublisher）1234@Bean(name = "hustrixMetricsPublisher", initMethod = "init", destroyMethod = "destory")public HystrixMetricsPublisher hystrixMetricsPublisher() &#123; return new MyHystrixMetricsPublisher();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243public class MyHystrixMetricsPublisher extends HystrixMetricsPublisher &#123; private static final Logger LOGGER = LoggerFactory.getLogger(MyHystrixMetricsPublisher.class); private final ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(Runtime.getRuntime().availableProcessors() * 2, new ThreadFactoryBuilder().setNameFormat("hystrixMetricsPublisherCommand-%d").build()); public void init() &#123; HystrixPlugins.getInstance().registerMetricsPublisher(this); &#125; @Override public HystrixMetricsPublisherCommand getMetricsPublisherForCommand(HystrixCommandKey commandKey, HystrixCommandGroupKey commandGroupKey, HystrixCommandMetrics metrics, HystrixCircuitBreaker circuitBreaker, HystrixCommandProperties properties) &#123; return () -&gt; scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; LOGGER.info("***********HystrixMetricsPublisherCommand***********"); LOGGER.info("commandKey.name:" + commandKey.name()); LOGGER.info("commandGroupKey.name:" + commandGroupKey.name()); LOGGER.info("metrics.executionTimeMean:" + metrics.getExecutionTimeMean()); //还可以打印其他数值，见HystrixRollingNumberEvent枚举 LOGGER.info("metrics.cumulativeCount.SUCCESS:" + metrics.getCumulativeCount(HystrixRollingNumberEvent.SUCCESS)); LOGGER.info("metrics.cumulativeCount.FAILURE:" + metrics.getCumulativeCount(HystrixRollingNumberEvent.FAILURE)); LOGGER.info("metrics.cumulativeCount.FALLBACK_SUCCESS:" + metrics.getCumulativeCount(HystrixRollingNumberEvent.FALLBACK_SUCCESS)); LOGGER.info("***************************************************"); &#125;, 1, 10, TimeUnit.SECONDS); &#125; @Override public HystrixMetricsPublisherThreadPool getMetricsPublisherForThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolMetrics metrics, HystrixThreadPoolProperties properties) &#123; return super.getMetricsPublisherForThreadPool(threadPoolKey, metrics, properties); &#125; @Override public HystrixMetricsPublisherCollapser getMetricsPublisherForCollapser(HystrixCollapserKey collapserKey, HystrixCollapserMetrics metrics, HystrixCollapserProperties properties) &#123; return super.getMetricsPublisherForCollapser(collapserKey, metrics, properties); &#125; public void destory() &#123; scheduledExecutorService.shutdown(); &#125;&#125; 通过上面的简单配置，我们可以在日志文件中打印出程序启动以来，各配置了Hystrix方法的运行情况，如下： ***********HystrixMetricsPublisherCommand***********commandKey.name:hellocommandGroupKey.name:hystrix_monitor_demometrics.executionTimeMean:0metrics.cumulativeCount.SUCCESS:4metrics.cumulativeCount.FAILURE:5metrics.cumulativeCount.FALLBACK_SUCCESS:79**************************************************************HystrixMetricsPublisherCommand***********commandKey.name:worldcommandGroupKey.name: hystrix_monitor_demometrics.executionTimeMean:0metrics.cumulativeCount.SUCCESS:18metrics.cumulativeCount.FAILURE:26metrics.cumulativeCount.FALLBACK_SUCCESS:65*************************************************** 这样，很简单的，我们通过查看日志，就能看到我们想要的数据，数据每过10秒（可以在代码中自己改）重新打印一次 二、简易的监控平台有了上面最简单的监控方式后，我们可能又有了更进一步的要求，能不能有一个统一的监控平台，不需要挨个服务器去看日志文件，所以有了如下的一个简单思路： 1、设计一张表，用于落地统计数据12345678910111213141516171819202122create table t_hystrix_monitor ( project_name varchar(200) not null default '' comment '项目名/集群名', group_key varchar(200) not null default '' comment 'group_key', command_key varchar(200) not null default '' comment 'command_key，约定为需要降级的方法标识', success bigint(20) not null default 0 comment '成功次数', failure bigint(20) not null default 0 comment '失败次数', timeout bigint(20) not null default 0 comment '超时次数', exception_thrown bigint(20) not null default 0 comment '异常次数', fallback_success bigint(20) not null default 0 comment 'fallback执行成功次数', fallback_failure bigint(20) not null default 0 comment 'fallback执行失败次数', fallback_missing bigint(20) not null default 0 comment 'fallback丢失次数', reserve1 bigint(20) not null default 0 comment '备用字段', reserve2 bigint(20) not null default 0 comment '备用字段', reserve3 bigint(20) not null default 0 comment '备用字段', reserve4 bigint(20) not null default 0 comment '备用字段', reserve5 bigint(20) not null default 0 comment '备用字段', reserve6 varchar(200) not null default '' comment '备用字段', reserve7 varchar(200) not null default '' comment '备用字段', reserve8 varchar(200) not null default '' comment '备用字段', reserve9 varchar(200) not null default '' comment '备用字段', primary key (project_name, group_key, command_key)); 里面只写了我们可能主要关注的一些数值，后续有其他需要可以写到扩展字段 2、配置监控（HystrixMetricsPublisher）这个地方的主要区别是，把记录日志的方式改为入库，入库的时候有个需要处理的问题就是metrics.getCumulativeCount()拿到的是启动以来的总计数值。为了保证集群情况以及服务器重启后可以正常进行统计，我们需要计算一个增量数据，然后不断的叠加。新的HystrixMetricsPublisher如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244public class MyHystrixMetricsPublisher extends HystrixMetricsPublisher &#123; private final ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(Runtime.getRuntime().availableProcessors() * 2, new ThreadFactoryBuilder().setNameFormat("hystrixMetricsPublisherCommand-%d").build()); /** * 上一次统计数据，用来做差值，计算增量数据 */ private final Map&lt;String, CumulativeCount&gt; lastCount = Maps.newConcurrentMap(); private ReentrantLock lock = new ReentrantLock(true); /** * 数据源，自行配置 */ @Inject private DataSource dataSource; public static MyHystrixMetricsPublisher INSTANCE; public void init() &#123; HystrixPlugins.getInstance().registerMetricsPublisher(this); //为了方便给jsp页面用来获取需要展示的数据 MyHystrixMetricsPublisher.INSTANCE = this; &#125; @Override public HystrixMetricsPublisherCommand getMetricsPublisherForCommand(HystrixCommandKey commandKey, HystrixCommandGroupKey commandGroupKey, HystrixCommandMetrics metrics, HystrixCircuitBreaker circuitBreaker, HystrixCommandProperties properties) &#123; return () -&gt; scheduledExecutorService.scheduleAtFixedRate(() -&gt; &#123; final Optional&lt;CumulativeCount&gt; changed = isChanged(metrics); if (changed.isPresent()) &#123; try ( Connection conn = dataSource.getConnection(); PreparedStatement pstmt = conn.prepareStatement("insert into t_hystrix_monitor(`project_name`, `group_key`, `command_key`, `success`, `failure`, `timeout`, `exception_thrown`, `fallback_success`, `fallback_failure`, `fallback_missing`) " + "values(?, ?, ?, ?, ?, ?, ?, ?, ?, ?) on duplicate key update " + "`success` = `success` + values(`success`), " + "`failure` = `failure` + values(`failure`), " + "`timeout` = `timeout` + values(`timeout`), " + "`exception_thrown` = `exception_thrown` + values(`exception_thrown`), " + "`fallback_success` = `fallback_success` + values(`fallback_success`), " + "`fallback_failure` = `fallback_failure` + values(`fallback_failure`), " + "`fallback_missing` = `fallback_missing` + values(`fallback_missing`)") ) &#123; pstmt.setString(1, "hystrix_monitor_demo"); pstmt.setString(2, commandGroupKey.name()); pstmt.setString(3, commandKey.name()); pstmt.setLong(4, changed.get().getSuccess()); pstmt.setLong(5, changed.get().getFailure()); pstmt.setLong(6, changed.get().getTimeout()); pstmt.setLong(7, changed.get().getExceptionThrown()); pstmt.setLong(8, changed.get().getFallbackSuccess()); pstmt.setLong(9, changed.get().getFallbackFailure()); pstmt.setLong(10, changed.get().getFallbackMissing()); System.out.println("updated, effect " + pstmt.executeUpdate() + " rows"); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, 1, 10, TimeUnit.SECONDS); &#125; /** * 判断数据是否变化并更新最新数据，返回差值 * * @param metrics 新数据 * @return 差值，如果没有变化，返回Optional.empty() */ private Optional&lt;CumulativeCount&gt; isChanged(HystrixCommandMetrics metrics) &#123; lock.lock(); try &#123; String key = metrics.getCommandGroup().name() + "." + metrics.getCommandKey().name(); CumulativeCount last = lastCount.get(key); CumulativeCount cumulativeCount = new CumulativeCount(); cumulativeCount.setSuccess(metrics.getCumulativeCount(HystrixRollingNumberEvent.SUCCESS)); cumulativeCount.setExceptionThrown(metrics.getCumulativeCount(HystrixRollingNumberEvent.EXCEPTION_THROWN)); cumulativeCount.setFailure(metrics.getCumulativeCount(HystrixRollingNumberEvent.FAILURE)); cumulativeCount.setFallbackFailure(metrics.getCumulativeCount(HystrixRollingNumberEvent.FALLBACK_FAILURE)); cumulativeCount.setFallbackMissing(metrics.getCumulativeCount(HystrixRollingNumberEvent.FALLBACK_MISSING)); cumulativeCount.setTimeout(metrics.getCumulativeCount(HystrixRollingNumberEvent.TIMEOUT)); cumulativeCount.setFallbackSuccess(metrics.getCumulativeCount(HystrixRollingNumberEvent.FALLBACK_SUCCESS)); lastCount.put(key, cumulativeCount); if (last == null) &#123; return Optional.of(cumulativeCount); &#125; else if (cumulativeCount.equals(last)) &#123; return Optional.empty(); &#125; else &#123; CumulativeCount diff = new CumulativeCount(); diff.setSuccess(cumulativeCount.getSuccess() - last.getSuccess()); diff.setExceptionThrown(cumulativeCount.getExceptionThrown() - last.getExceptionThrown()); diff.setFailure(cumulativeCount.getFailure() - last.getFailure()); diff.setFallbackFailure(cumulativeCount.getFallbackFailure() - last.getFallbackFailure()); diff.setFallbackMissing(cumulativeCount.getFallbackMissing() - last.getFallbackMissing()); diff.setTimeout(cumulativeCount.getTimeout() - last.getTimeout()); diff.setFallbackSuccess(cumulativeCount.getFallbackSuccess() - last.getFallbackSuccess()); return Optional.of(diff); &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; @Override public HystrixMetricsPublisherThreadPool getMetricsPublisherForThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolMetrics metrics, HystrixThreadPoolProperties properties) &#123; return super.getMetricsPublisherForThreadPool(threadPoolKey, metrics, properties); &#125; @Override public HystrixMetricsPublisherCollapser getMetricsPublisherForCollapser(HystrixCollapserKey collapserKey, HystrixCollapserMetrics metrics, HystrixCollapserProperties properties) &#123; return super.getMetricsPublisherForCollapser(collapserKey, metrics, properties); &#125; /** * 用来获取统计数据，给前端页面做展示用，可以忽略，最主要的是我们将我们最关心的数据已经落库 * * @return 统计数据 */ public Map&lt;String, Map&lt;String, Long&gt;&gt; metrics() &#123; try ( Connection conn = dataSource.getConnection(); Statement stmt = conn.createStatement(); ResultSet rs = stmt.executeQuery("select project_name, group_key, command_key, sum(success) as success, sum(failure) as failure, sum(fallback_success) as fallback_success, sum(timeout) as timeout, sum(exception_thrown) as exception_thrown, " + "sum(fallback_failure) as fallback_failure from t_hystrix_monitor group by project_name, group_key, command_key") ) &#123; Map&lt;String, Map&lt;String, Long&gt;&gt; metrics = Maps.newHashMap(); while (rs.next()) &#123; String key = rs.getString("project_name") + "." + rs.getString("group_key") + "." + rs.getString("command_key"); Map&lt;String, Long&gt; count = Maps.newHashMap(); count.put("SUCCESS", rs.getLong("success")); count.put("FAILURE", rs.getLong("failure")); count.put("FALLBACK_SUCCESS", rs.getLong("fallback_success")); count.put("TIMEOUT", rs.getLong("timeout")); count.put("FALLBACK_FAILURE", rs.getLong("fallback_failure")); count.put("EXCEPTION_THROWN", rs.getLong("exception_thrown")); metrics.put(key, count); &#125; return metrics; &#125; catch (SQLException e) &#123; e.printStackTrace(); return Maps.newHashMap(); &#125; &#125; public void destory() &#123; scheduledExecutorService.shutdown(); &#125;&#125;public class CumulativeCount &#123; private long success; private long failure; private long timeout; private long exceptionThrown; private long fallbackSuccess; private long fallbackFailure; private long fallbackMissing; public long getSuccess() &#123; return success; &#125; public void setSuccess(long success) &#123; this.success = success; &#125; public long getFailure() &#123; return failure; &#125; public void setFailure(long failure) &#123; this.failure = failure; &#125; public long getTimeout() &#123; return timeout; &#125; public void setTimeout(long timeout) &#123; this.timeout = timeout; &#125; public long getExceptionThrown() &#123; return exceptionThrown; &#125; public void setExceptionThrown(long exceptionThrown) &#123; this.exceptionThrown = exceptionThrown; &#125; public long getFallbackSuccess() &#123; return fallbackSuccess; &#125; public void setFallbackSuccess(long fallbackSuccess) &#123; this.fallbackSuccess = fallbackSuccess; &#125; public long getFallbackFailure() &#123; return fallbackFailure; &#125; public void setFallbackFailure(long fallbackFailure) &#123; this.fallbackFailure = fallbackFailure; &#125; public long getFallbackMissing() &#123; return fallbackMissing; &#125; public void setFallbackMissing(long fallbackMissing) &#123; this.fallbackMissing = fallbackMissing; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; CumulativeCount that = (CumulativeCount) o; return success == that.success &amp;&amp; failure == that.failure &amp;&amp; timeout == that.timeout &amp;&amp; exceptionThrown == that.exceptionThrown &amp;&amp; fallbackSuccess == that.fallbackSuccess &amp;&amp; fallbackFailure == that.fallbackFailure &amp;&amp; fallbackMissing == that.fallbackMissing; &#125; @Override public int hashCode() &#123; return Objects.hash(success, failure, timeout, exceptionThrown, fallbackSuccess, fallbackFailure, fallbackMissing); &#125; @Override public String toString() &#123; return "CumulativeCount&#123;" + "success=" + success + ", failure=" + failure + ", timeout=" + timeout + ", exceptionThrown=" + exceptionThrown + ", fallbackSuccess=" + fallbackSuccess + ", fallbackFailure=" + fallbackFailure + ", fallbackMissing=" + fallbackMissing + '&#125;'; &#125;&#125; 上面代码中有一段是我本地做测试的时候给前端JSP页面用的，配合ECharts简单输出了一个饼图，在此就忽略不写了，我们最关心的数据已经落库了，后续是用表格还是什么形式展示出来都可以。 3、扩展 设计表的时候，我们可以加入时间字段，按天汇总数据，这样统计的时候可以按天为纬度，统计某个时间段的情况 数据收集方面，可以通过MQ订阅的方式，接入监控的系统向监控平台定时发送增量信息，然后监控平台统一做入库汇总]]></content>
      <categories>
        <category>Hystrix</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Hystrix</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事件组件-EventBus]]></title>
    <url>%2F2018%2F08%2F30%2F%E4%BA%8B%E4%BB%B6%E7%BB%84%E4%BB%B6-EventBus%2F</url>
    <content type="text"><![CDATA[去年底一直在做订单服务的重构工作，在设计的时候，通过梳理原代码发现的主要问题就是代码太复杂，主次逻辑混在一起，次要逻辑会影响主逻辑，所以这次重构的核心放在了主次逻辑剥离以及主次逻辑组织的问题上，自然而然的，想到了异步编程以及事件模型，主逻辑执行完通过发送事件来触发次要逻辑。 关于事件模型的选择，由于guava用的比较多，很自然的想到了guava中的event bus，简单实用示例如下（如果不了解，可以自己去guava中看一下源码，总的来说还是比较简单易懂）： public class Main { public static final int AVAILABLE_PROCESSOR = Runtime.getRuntime().availableProcessors(); public static final int IO_THREAD_NUM = AVAILABLE_PROCESSOR * 2 + 1; public static final int CPU_THREAD_NUM = AVAILABLE_PROCESSOR + 1; public static final int DEFAULT_THREAD_POOL_WORK_QUEUE_SIZE = 1024; public static void main(String[] args) throws Exception { ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(IO_THREAD_NUM, IO_THREAD_NUM, 0, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(DEFAULT_THREAD_POOL_WORK_QUEUE_SIZE), new OrderEventHandlerThreadFactory()); EventBus eventBus = new EventBus(); eventBus.register((EventListener) o -&gt; System.out.println(Thread.currentThread().getName() + ":onObject")); eventBus.post(new Object()); EventBus asyncEventBus = new AsyncEventBus(threadPoolExecutor); asyncEventBus.register((EventListener) o -&gt; System.out.println(Thread.currentThread().getName() + ":onObject")); asyncEventBus.post(new Object()); threadPoolExecutor.shutdown(); } /** * 线程工厂，用于创建线程，主要为了方便线程命名 */ private static class OrderEventHandlerThreadFactory implements ThreadFactory { private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private static final String NAME_PREFIX = "orderEvent-pool-"; OrderEventHandlerThreadFactory() { SecurityManager sm = System.getSecurityManager(); group = sm != null ? sm.getThreadGroup() : Thread.currentThread().getThreadGroup(); } @Override public Thread newThread(Runnable runnable) { return new Thread(group, runnable, NAME_PREFIX + threadNumber.getAndIncrement()); } } interface EventListener { @Subscribe @AllowConcurrentEvents void onObject(Object o); } } 输出结果为： main:onObjectorderEvent-pool-1:onObject 最开始的时候，我们采用的是上面的方案，但慢慢的，我们有了新的要求，比如，灵活的控制同步和异步，guava的event bus控制同步异步需要两个event bus，一个普通的EventBus，一个AsyncEventBus，无法在同一个event bus中灵活控制同步和异步，还有一个问题就是，同步的情况下，无法给Listener排序，所以，在这种情况下，我们基于guava event bus的源码做了适合我们自己的改造，核心的类图如下： 核心流程为: 注册Listener时，EventBus通过SubscriberRegistry管理Event和Subscriber的关联关系，这个关联关系是通过解析传入的Listener类中含有@Subscribe注解的方法，这个注解有可能是加在Listener类的父类或者其实现的接口中的，会一直向上找，事件类型为方法入参，然后将所有信息汇总封装为Subscriber 发送Event时，EventBus通过SubscriberRegistry获取该Event或者该Event父类对应的所有Subscriber，然后传递到Dispatcher中，我们提供了OrderedDispatcher实现，该实现会通过Subscriber的order字段对其进行排序，然后依次调用Subscriber的process(event)方法，该方法会根据allowConcurrency和async等字段来决定方法怎么调用 如果执行的过程中出错，会通过SubscriberExceptionHandler来决定怎么处理 如果Event没有对应的Subscriber，封装为DeadEvent发送出去 整个流程和Guava EventBus是高度类似的，除了Dispatcher的实现以及Subscriber的同步、异步处理 示例代码如下： public class Main { public static final int AVAILABLE_PROCESSOR = Runtime.getRuntime().availableProcessors(); public static final int IO_THREAD_NUM = AVAILABLE_PROCESSOR * 2 + 1; public static final int CPU_THREAD_NUM = AVAILABLE_PROCESSOR + 1; public static final int DEFAULT_THREAD_POOL_WORK_QUEUE_SIZE = 1024; public static void main(String[] args) throws Exception { ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(IO_THREAD_NUM, IO_THREAD_NUM, 0, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(DEFAULT_THREAD_POOL_WORK_QUEUE_SIZE), new OrderEventHandlerThreadFactory()); EventBus eventBus = EventBus.builder().setIdentifier("test").setExecutor(threadPoolExecutor).build(); eventBus.register(new EventListener() { @Override public void onEvent1(Object event) { System.out.println(Thread.currentThread().getName() + ":onEvent1"); } @Override public void onEvent2(Object event) { System.out.println(Thread.currentThread().getName() + ":onEvent2"); } @Override public void onEventAsync(Object event) { System.out.println(Thread.currentThread().getName() + ":onEventAsync"); } }); eventBus.post(new Object()); threadPoolExecutor.shutdown(); } /** * 线程工厂，用于创建线程，主要为了方便线程命名 */ private static class OrderEventHandlerThreadFactory implements ThreadFactory { private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private static final String NAME_PREFIX = "orderEvent-pool-"; OrderEventHandlerThreadFactory() { SecurityManager sm = System.getSecurityManager(); group = sm != null ? sm.getThreadGroup() : Thread.currentThread().getThreadGroup(); } @Override public Thread newThread(Runnable runnable) { return new Thread(group, runnable, NAME_PREFIX + threadNumber.getAndIncrement()); } } public interface EventListener { @Subscribe(order = 2) void onEvent2(Object event); @Subscribe(order = 1) void onEvent1(Object event); @Subscribe(async = true) void onEventAsync(Object event); } } 输出结果为： main:onEvent1main:onEvent2orderEvent-pool-1:onEventAsync 对改造版EventBus代码感兴趣的可以去我的github中查看，地址为：EventBus 没有解决的问题：如何保证EventBus不丢事件，比如主逻辑执行完，事件发送之后，次要逻辑没有执行或执行了一部分发生宕机。目前在我们的系统中，次要逻辑都是一些短信、通知之类的，丢失也无所谓。]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>事件模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC中的一些锁以及核心AQS类]]></title>
    <url>%2F2018%2F06%2F04%2FJUC%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E9%94%81%E4%BB%A5%E5%8F%8A%E6%A0%B8%E5%BF%83AQS%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[已经研究完一段时间了，需要抽时间好好组织一下；CAS操作volatile、内存屏障（保证可见性、一致性、Happens-Before）Node.waitStatusConditionObject施工中…未完待续 前段时间认真研究了一下JUC中的一些锁以及核心的AQS类，在此做个总结，写的可能不是特别好。 1、ReentrantLock大部分人接触到的第一个juc中的锁，可能就是这个类了，我们可以通过try-finally语句块调用其lock和unlock来实现加锁和释放锁。 1.1、ReentrantLock实现查看ReentrantLock的源代码，会发现ReentrantLock的代码很少，核心代码是其一个静态内部抽象类Sync（juc中大部分锁都有一个静态内部抽象类Sync），提供了两个静态内部实现类，FairSync和NonfairSync，分别用于实现公平锁和非公平锁，ReentrantLock的精简代码如下（主要方法，先不考虑序列化）： 1234567891011121314151617181920212223242526272829303132333435public class ReentrantLock implements Lock &#123; private final Sync sync; public ReentrantLock() &#123; sync = new NonfairSync(); &#125; public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; public void lock() &#123; sync.lock(); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock() &#123; return sync.nonfairTryAcquire(1); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125;&#125; 上线代码是我们使用ReentrantLock时会用到的主要方法，可以看到，所有的核心，都是Sync，查看Sync的源代码时，会发现，所有的核心机制，指向了一个类：AbstractQueuedSynchronizer，所以要想理解ReentrantLock，必须先理解AbstractQueuedSynchronizer。 2、AbstractQueuedSynchronizerAbstractQueuedSynchronizer的源码中，对该类有很详尽的javadoc说明，这里就不在赘述，直接进入正题。 AbstractQueuedSynchronizer从名字上看，就可以知道其和队列有关，通过javadoc和源码，我们也可以知道，其核心就是一个FIFO（先进先出）的等待队列，通过维护该队列、队列中每个Node的状态以及一个公共的state，来实现加锁和解锁。 首先，我们需要了解AbstractQueuedSynchronizer中的一些基本类和字段。 2.1、Node类Node类可以说是AbstractQueuedSynchronizer中的核心类，AbstractQueuedSynchronizer维护了一个FIFO的等待队列，Node类就是这个队列的节点，下面是Node类中的一些核心概念（数据结构）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748static final class Node &#123; /** * 共享模式 */ static final Node SHARED = new Node(); /** * 独占模式 */ static final Node EXCLUSIVE = null; /** * 表示节点持有的Thread已经取消执行 */ static final int CANCELLED = 1; /** * 表示节点持有的Thread需要unparking(唤醒） */ static final int SIGNAL = -1; /** * 表示节点持有的Thread在等待某个Condition */ static final int CONDITION = -2; /** * 表示下一个acquireShared操作无条件传递 */ static final int PROPAGATE = -3; /** * 节点状态 */ volatile int waitStatus; /** * 上一节点 */ volatile Node prev; /** * 下一节点 */ volatile Node next; /** * 节点持有的线程 */ volatile Thread thread; /** * 当前节点的nextWaiter，主要用于连接ConditionObject队列 */ Node nextWaiter;&#125; 上面代码中，有很大一部分是定义常量，组成Node数据结构的只有waitStatue、prev、next、thread、nextWaiter。 2.2、AbstractQueuedSynchronizer类AbstractQueuedSynchronizer类中的一些主要字段如下： 1234567891011121314/** * 等待队列头 */private transient volatile Node head;/** * 等待队列尾 */private transient volatile Node tail;/** * 同步状态 */private volatile int state; 2.3、ConditionObjectCondition是一个接口，其作用类似Object中的wait/notify，接口定义了类似的await/signal方法。 AbstractQueuedSynchronizer中默认提供了一个Condition接口的实现，是一个内部类，主要的定义如下： 123456789101112public class ConditionObject implements Condition &#123; /** * Condition队列头 */ private transient Node firstWaiter; /** * Condition队列尾 */ private transient Node lastWaiter; //忽略方法已经序列化部分...后续解析&#125; 2.4、AbstractQueuedSynchronizer常用方法源码解析在AbstractQueuedSynchronizer中，除了tryAcquire/tryRelease/tryAcquireShared/tryReleaseShared/isHeldExclusively需要我们自己根据实际情况自己实现之外，其他的所有方法都是已经实现好，并且不可覆盖的（final修饰）。 2.4.1 acquire方法有了上面的基本概念以及数据结构以后，我们来看看最常用的acquire方法，该方法主要用来实现互斥锁： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 上面的代码很简单，从字面上看，就是调用我们自己实现的tryAcquire方法，该方法主要是通过getState、compareAndSetState等方法来操作state，决定是否可以获取到资源。 如果获取到资源，直接执行完毕，如果没有获取到，那么就把当前线程封装成一个EXCLUSIVE的Node，放入等待队列，然后调用acquireQueued方法。addWaiter方法如下： 123456789101112131415161718192021222324252627282930private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 上面的代码也很容易理解，总的思路就是通过自旋+CAS操作，将新生成的Node插入队列，并返回新生成的Node。(注意，如果原队列是一个空队列，会先插入一个空节点作为头节点，见代码18、19行) 拿到新生成的Node后，对其调用acquireQueued方法，acquireQueued方法可以说是整个同步器的核心方法，代码如下： 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 上面的代码概括起来就是（正常流程）：如果当前节点的前一个节点是head节点并且当前节点获取资源成功，那么将当前节点设置为head节点，释放head节点并返回；如果上一个节点不是head节点，或者当前节点没有请求到资源，那么通过shouldParkAfterFailedAcquire方法判断当前线程是否需要挂起来决定自旋重试还是挂起(整个过程不会响应interrupt，只有在最终获得锁后，返回是否线程是否被interrupted)。 因为第一个节点有可能是空节点，所以如果当前节点的前一个节点是空节点的话，也要尝试去获取资源 下面是shouldParkAfterFailedAcquire的逻辑： 1234567891011121314151617181920212223242526private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * 如果上一节点是等待唤醒状态，那么当前节点需要park(挂起） */ return true; if (ws &gt; 0) &#123; /* * 如果上一节点是取消状态（目前大于0的状态只有取消），那么移除取消的节点 * 通过do-while循环直到当前节点的上一个节点的状态小于等于0 * 然后在此尝试获取锁 */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * 状态是0或者PROPAGATE. 更新上一个节点的状态为Node.SIGNAL， * 并在此尝试获取锁 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 上面代码的核心功能就是，如果当前节点的上一个节点是SIGNAL状态，那么返回true，表示线程需要park（这个时候当前节点的状态是默认的0）；如果当前节点的上一节点应该被移除，那么通过do-while一直向前移，将需要移除的子链断开，当前线程不需要park；如果上一节点的状态是0或者PROPAGATE，那么将上一节点的状态通过CAS操作置为SIGNAL，当前线程不需要park。 如果在acquireQueued自旋的过程中，发生了未知错误，通过如下代码来取消请求： 12345678910111213141516171819202122232425262728293031323334353637383940414243private void cancelAcquire(Node node) &#123; // Ignore if node doesn't exist if (node == null) return; node.thread = null; // Skip cancelled predecessors Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; 至此，acquire源码解析完毕。 2.4.2 release方法下面看一下和acquire对应的release方法，源码如下： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 上面的方法也很简单，一个核心就是我们要自己通过tryAcquire和tryRelease控制好state的状态。unparkSuccessor代码如下： 1234567891011121314151617181920212223242526private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 上面的代码首先会判断头结点的状态，如果状态小于0，会]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava限流器-RateLimiter]]></title>
    <url>%2F2018%2F05%2F26%2FGuava%E9%99%90%E6%B5%81%E5%99%A8-RateLimiter%2F</url>
    <content type="text"><![CDATA[最简单的限流思想最近在学习Guava使用的时候看到了RateLimiter，也就是限流器，其类的注释里面有提到最简单的限流思想如下： The simplest way to maintain a rate of QPS is to keep the timestamp of the last granted request, and ensure that (1/QPS) seconds have elapsed since then. For example, for a rate of QPS=5 (5 tokens per second), if we ensure that a request isn’t granted earlier than 200ms after the last one, then we achieve the intended rate. If a request comes and the last request was granted only 100ms ago, then we wait for another 100ms. At this rate, serving 15 fresh permits(i.e. for an acquire(15) request) naturally takes 3 seconds. 简单来说，就是我们可以通过记录最近一次被授权请求的请求时间，来达到限流的目的。比如说QPS为5（每秒允许通过5个请求），那么我们可以认为是两个请求之间需要间隔1/QPS秒，也就是200毫秒，通过判断当前请求时间和最近一次授权时间的时间间隔是否大于等于200毫秒来决定当前请求是否允许执行。当然，如果小于200ms我们也可以选择更新最新授权时间+等待，或者直接抛弃两种处理方式。 下面我们来看一下Guava里面到底是怎么实现的。 Guava中RateLimiter层次结构 常见用法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class RateLimiterTest &#123; public static void main(String[] args) throws Exception &#123; smoothBursty(); smoothWarmingUp(); &#125; public static void smoothBursty() throws Exception &#123; System.out.println("-----------------SmoothBursty-----------------"); RateLimiter rateLimter = RateLimiter.create(1); Stopwatch started = Stopwatch.createStarted(); rateLimter.acquire(); System.out.println("A1:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.MILLISECONDS.sleep(300); rateLimter.acquire(); System.out.println("A2:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.SECONDS.sleep(6); rateLimter.acquire(5); System.out.println("A3:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.MILLISECONDS.sleep(1500); rateLimter.acquire(); System.out.println("A4:" + started.elapsed(TimeUnit.SECONDS)); System.out.println("-----------------SmoothBursty-----------------"); &#125; public static void smoothWarmingUp() throws Exception &#123; System.out.println("-----------------SmoothWarmingUp-----------------"); RateLimiter rateLimter = RateLimiter.create(1, 3, TimeUnit.SECONDS); Stopwatch started = Stopwatch.createStarted(); rateLimter.acquire(); System.out.println("A1:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A2:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A3:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A4:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A5:" + started.elapsed(TimeUnit.MILLISECONDS)); TimeUnit.SECONDS.sleep(5); rateLimter.acquire(); System.out.println("A6:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A7:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A8:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A9:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A10:" + started.elapsed(TimeUnit.MILLISECONDS)); System.out.println("-----------------SmoothWarmingUp-----------------"); &#125;&#125; 上面的代码没什么实际业务场景，仅仅是为了验证一些东西。 SmoothBurstySmoothBursty翻译成中文，是平稳和突发，意思就是这个限流器可以平稳限流，也可以应对突发的大量请求。 SmoothBursty的一些关键点 令牌法 采用令牌算法来进行限流，速率不固定 囤积令牌 默认最多囤积一秒的令牌数 下一次可通行时间点 记录下一次开始发放令牌的时间点 前人挖坑，后人埋 如果当前请求时间大于记录的下一次可用时间点，不管请求多少令牌，直接放过，根据请求的令牌数以及当前囤积的令牌数来将“下一次可用时间点”往后推；如果当前求情时间小于记录的下一次可用时间点，则wait一段时间（这段时间=下一次可用时间点 - 当前请求时间），然后将下一次可用时间点往后推，推后的时长 = 当前请求令牌数 * 生成一个令牌需要的时间 SmoothBursty中的一些名词解释 maxBurstSeconds 可以理解为RateLimiter未被使用时，可以囤积多少秒的令牌，Guava默认为1且没有提供修改方法 storedPermits 当前囤积的令牌数 maxPermits 最大可囤积令牌数 stableIntervalMicros 每生成一个令牌的时间间隔，比如QPS为5，那么每200ms生成一个令牌 nextFreeTicketMicros 可以理解为下次产生可用令牌的时间，这个时间每次acquire的时候都会更新，只能是一个将来的时间点 stopwatch 可以理解为一个计时器，在RateLimiter被创建的时候开始计时 mutexDoNotUseDirectly 锁对象 简单工作原理图如上图所示，横向的矩形框表示时间，假设QPS为1，每一格为1秒,上面的箭头表示下次允许请求通过的时间点（nextFreeTicketMicros），下面的箭头表示每次请求，针对每次请求做分析（只针对acquire，不包含tryAcquire）： A1，请求1个令牌，此时限流器刚启动，nextFreeTicketMicros为N0，接收到A1请求后，允许请求通过，当前没有令牌可用，所以透支一个，nextFreeTicketMicros会被推到N1（因为生成一个令牌需要1秒） A2，请求1个令牌，由于nextFreeTicketMicros为N1，所以该请求需要wait一段时间，这段时间等于图中A2到N1的黄色部分，然后生成A2所需要的令牌又需要1秒钟，所以nextFreeTicketMicros会被推到N2 A3，请求5个令牌，由于N2到N7没有请求产生，所以到了A3请求时，会有一个令牌囤积（QPS为1，SmoothBursty默认囤积1秒产生的令牌），然后nextFreeTicketMicros首先会被推到N7，由于A3请求5个令牌，用掉囤积的一个后，还需要透支4个，所以nextFreeTicketMicros又会被推到N11，A3请求通过 A4，请求1个令牌，由于nextFreeTicketMicros为N11，所以A4请求需要wait一段时间，这段时间等于图中A4到N11的黄色部分，生成A4所需要的令牌需要1秒，所以nextFreeTicketMicros会被推到N12 下面的代码可以用来验证上面的流程： 1234567891011121314151617public class RateLimiterTest &#123; public static void main(String[] args) throws Exception &#123; RateLimiter rateLimter = RateLimiter.create(1); Stopwatch started = Stopwatch.createStarted(); rateLimter.acquire(); System.out.println("A1:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.MILLISECONDS.sleep(300); rateLimter.acquire(); System.out.println("A2:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.SECONDS.sleep(6); rateLimter.acquire(5); System.out.println("A3:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.MILLISECONDS.sleep(1500); rateLimter.acquire(); System.out.println("A4:" + started.elapsed(TimeUnit.SECONDS)); &#125;&#125; 打印结果为： A1:0A2:1A3:7A4:11 分别代表A1请求在第0秒通过，A2在第1秒通过，A3在第7秒通过，A4在第11秒通过 至于tryAcquire，就是判断当前请求时间是否 &gt;= nextFreeTicketMicros - timeout，如果成立，走类似acquire的逻辑，返回true；如果当前请求时间加上timeout时长还达不到nextFreeTicketMicros，直接返回false 关键方法源码关键代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public double acquire(int permits) &#123; //获得所需令牌要wait多久 long microsToWait = reserve(permits); //sleep stopwatch.sleepMicrosUninterruptibly(microsToWait); return 1.0 * microsToWait / SECONDS.toMicros(1L);&#125;final long reserve(int permits) &#123; //校验permits必须大于0 checkPermits(permits); synchronized (mutex()) &#123; return reserveAndGetWaitLength(permits, stopwatch.readMicros()); &#125;&#125;final long reserveAndGetWaitLength(int permits, long nowMicros) &#123; //获得令牌可用时刻 long momentAvailable = reserveEarliestAvailable(permits, nowMicros); //通过令牌可用时刻 - 当前请求时刻来决定当前请求是否需要sleep return max(momentAvailable - nowMicros, 0);&#125;/** * 核心方法 */final long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123; resync(nowMicros); long returnValue = nextFreeTicketMicros; //本次请求消耗多少囤积的令牌 double storedPermitsToSpend = min(requiredPermits, this.storedPermits); //本次请求需要新生成多少令牌 double freshPermits = requiredPermits - storedPermitsToSpend; //对于SmoothBursty来说，计算生成freshPermits个令牌需要多久 long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); //将nextFreeTicketMicros向后推，推后的时间等于生成freshPermits个令牌所需要的时间 this.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros); //扣减消耗的囤积令牌 this.storedPermits -= storedPermitsToSpend; //返回的是当前请求来临时的nextFreeTicketMicros return returnValue;&#125;void resync(long nowMicros) &#123; /* * 如果当前请求时间大于nextFreeTicketMicros，计算囤积令牌并将nextFreeTicketMicros设置为当前请求时间 * nextFreeTicketMicros只能是现在或者将来，如果是一个过去的时间，会被同步为现在 */ if (nowMicros &gt; nextFreeTicketMicros) &#123; double newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros(); storedPermits = min(maxPermits, storedPermits + newPermits); nextFreeTicketMicros = nowMicros; &#125;&#125;public boolean tryAcquire(int permits, long timeout, TimeUnit unit) &#123; long timeoutMicros = max(unit.toMicros(timeout), 0); checkPermits(permits); long microsToWait; synchronized (mutex()) &#123; long nowMicros = stopwatch.readMicros(); if (!canAcquire(nowMicros, timeoutMicros)) &#123; return false; &#125; else &#123; microsToWait = reserveAndGetWaitLength(permits, nowMicros); &#125; &#125; stopwatch.sleepMicrosUninterruptibly(microsToWait); return true;&#125;private boolean canAcquire(long nowMicros, long timeoutMicros) &#123; //queryEarliestAvailable(nowMicros) = nextFreeTicketMicros return queryEarliestAvailable(nowMicros) - timeoutMicros &lt;= nowMicros;&#125; SmoothWarmingUp与SmoothBursty的主要区别 漏斗法 采用漏斗法限流，会有预热阶段，预热阶段的QPS要小于预期值，稳定阶段QPS等于预期值 storedPermits和maxPermits的含义改变，storedPermits的含义更多的是有多久没有访问过限流器，用来计算预热时间，maxPermits还是其边界值 花费storedPermits也会将nextFreeTicketMicros往后推 RateLimiter空闲时，令牌的生成间隔不是stableIntervalMicros，而是maxPermits / warmupPeriod，所以，从0填满storedPermits耗时为warmupPeriod 工作原理可以通过官方的一段javadoc来了解SmoothWarmingUp的工作原理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * This implements the following function where coldInterval = coldFactor * stableInterval. * * &lt;pre&gt; * ^ throttling * | * cold + / * interval | /. * | / . * | / . ← "warmup period" is the area of the trapezoid between * | / . thresholdPermits and maxPermits * | / . * | / . * | / . * stable +----------/ WARM . * interval | . UP . * | . PERIOD. * | . . * 0 +----------+-------+--------------→ storedPermits * 0 thresholdPermits maxPermits * &lt;/pre&gt; * * Before going into the details of this particular function, let's keep in mind the basics: * * &lt;ol&gt; * &lt;li&gt;The state of the RateLimiter (storedPermits) is a vertical line in this figure. * &lt;li&gt;When the RateLimiter is not used, this goes right (up to maxPermits) * &lt;li&gt;When the RateLimiter is used, this goes left (down to zero), since if we have * storedPermits, we serve from those first * &lt;li&gt;When _unused_, we go right at a constant rate! The rate at which we move to the right is * chosen as maxPermits / warmupPeriod. This ensures that the time it takes to go from 0 to * maxPermits is equal to warmupPeriod. * &lt;li&gt;When _used_, the time it takes, as explained in the introductory class note, is equal to * the integral of our function, between X permits and X-K permits, assuming we want to * spend K saved permits. * &lt;/ol&gt; * * &lt;p&gt;In summary, the time it takes to move to the left (spend K permits), is equal to the area of * the function of width == K. * * &lt;p&gt;Assuming we have saturated demand, the time to go from maxPermits to thresholdPermits is * equal to warmupPeriod. And the time to go from thresholdPermits to 0 is warmupPeriod/2. (The * reason that this is warmupPeriod/2 is to maintain the behavior of the original implementation * where coldFactor was hard coded as 3.) * * &lt;p&gt;It remains to calculate thresholdsPermits and maxPermits. * * &lt;ul&gt; * &lt;li&gt;The time to go from thresholdPermits to 0 is equal to the integral of the function * between 0 and thresholdPermits. This is thresholdPermits * stableIntervals. By (5) it is * also equal to warmupPeriod/2. Therefore * &lt;blockquote&gt; * thresholdPermits = 0.5 * warmupPeriod / stableInterval * &lt;/blockquote&gt; * &lt;li&gt;The time to go from maxPermits to thresholdPermits is equal to the integral of the * function between thresholdPermits and maxPermits. This is the area of the pictured * trapezoid, and it is equal to 0.5 * (stableInterval + coldInterval) * (maxPermits - * thresholdPermits). It is also equal to warmupPeriod, so * &lt;blockquote&gt; * maxPermits = thresholdPermits + 2 * warmupPeriod / (stableInterval + coldInterval) * &lt;/blockquote&gt; * &lt;/ul&gt; */ 简单流程验证代码： 1234567891011121314151617181920212223242526272829public class RateLimiterTest &#123; public static void main(String[] args) throws Exception &#123; RateLimiter rateLimter = RateLimiter.create(1, 3, TimeUnit.SECONDS); Stopwatch started = Stopwatch.createStarted(); rateLimter.acquire(); System.out.println("A1:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A2:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A3:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A4:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A5:" + started.elapsed(TimeUnit.MILLISECONDS)); TimeUnit.SECONDS.sleep(5); rateLimter.acquire(); System.out.println("A6:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A7:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A8:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A9:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A10:" + started.elapsed(TimeUnit.MILLISECONDS)); &#125; &#125; 输出结果: A1:1A2:2338A3:3500A4:4504A5:5500A6:10501A7:12835A8:14002A9:15006A10:16004 可以看到，请求A1和A2间隔为2000多毫秒，A2和A3间隔1160毫秒左右，A3、A4、A5之间间隔基本为1000毫秒，然后sleep一段时间后，发现A6/7/8/9/10之间的间隔和A1/2/3/4/5类似 关键方法源码扩展阅读常见的限流算法 计数法 滑动窗口 漏斗法 令牌法]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>限流器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PropertyDescriptor使用时遇到的坑]]></title>
    <url>%2F2018%2F05%2F25%2FPropertyDescriptor%E4%BD%BF%E7%94%A8%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[有一段时间特别喜欢链式编程，然后把自己的IDEA中自动生成getters and setters的setters模板设置成了Builder模式，生成的代码如下： 12345678910111213public class Person &#123; privat String name; public String getName() &#123; return this.name; &#125; public Person setName(String name) &#123; this.name = name; return this; &#125; &#125; 相信有不少人也喜欢这么写，这样写起来比单独再写一个Builder要简单很多，但是在最近遇到一个问题，就是在使用PropertyDescriptor的时候，会遇到java.beans.IntrospectionException: Method not found: setName的问题，依稀这段代码在很久以前使用的时候还是没有问题的，为了查明问题，翻阅了PropertyDescriptor的源码，发现在JDK1.7以及1.7之后，PropertyDescriptor类的getWriteMethod方法发成了改变，具体如下： 红框部分代码，是在1.7以及1.7以后新加入的，对set方法的返回值做了约束，返回值必须为void。 JDK为什么要这么改？个人猜想有两点，一是JavaBean规范，再一个可能是因为Java中的方法特征签名和字节码层面的方法特征签名不一致的问题，在Java语言中，方法的特征签名包括方法名、参数顺序以及参数类型，在字节码层面，方法签名特征还多了返回值以及受检查异常列表。所以，为了更好的兼容性，还是老老实实写完整的Builder模式吧。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
