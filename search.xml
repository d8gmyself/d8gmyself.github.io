<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[事件组件-EventBus]]></title>
    <url>%2F2018%2F08%2F30%2F%E4%BA%8B%E4%BB%B6%E7%BB%84%E4%BB%B6-EventBus%2F</url>
    <content type="text"><![CDATA[去年底一直在做订单服务的重构工作，在设计的时候，通过梳理原代码发现的主要问题就是代码太复杂，主次逻辑混在一起，次要逻辑会影响主逻辑，所以这次重构的核心放在了主次逻辑剥离以及主次逻辑组织的问题上，自然而然的，想到了异步编程以及事件模型，主逻辑执行完通过发送事件来触发次要逻辑。 关于事件模型的选择，由于guava用的比较多，很自然的想到了guava中的event bus，简单实用示例如下（如果不了解，可以自己去guava中看一下源码，总的来说还是比较简单易懂）： public class Main { public static final int AVAILABLE_PROCESSOR = Runtime.getRuntime().availableProcessors(); public static final int IO_THREAD_NUM = AVAILABLE_PROCESSOR * 2 + 1; public static final int CPU_THREAD_NUM = AVAILABLE_PROCESSOR + 1; public static final int DEFAULT_THREAD_POOL_WORK_QUEUE_SIZE = 1024; public static void main(String[] args) throws Exception { ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(IO_THREAD_NUM, IO_THREAD_NUM, 0, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(DEFAULT_THREAD_POOL_WORK_QUEUE_SIZE), new OrderEventHandlerThreadFactory()); EventBus eventBus = new EventBus(); eventBus.register((EventListener) o -&gt; System.out.println(Thread.currentThread().getName() + ":onObject")); eventBus.post(new Object()); EventBus asyncEventBus = new AsyncEventBus(threadPoolExecutor); asyncEventBus.register((EventListener) o -&gt; System.out.println(Thread.currentThread().getName() + ":onObject")); asyncEventBus.post(new Object()); threadPoolExecutor.shutdown(); } /** * 线程工厂，用于创建线程，主要为了方便线程命名 */ private static class OrderEventHandlerThreadFactory implements ThreadFactory { private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private static final String NAME_PREFIX = "orderEvent-pool-"; OrderEventHandlerThreadFactory() { SecurityManager sm = System.getSecurityManager(); group = sm != null ? sm.getThreadGroup() : Thread.currentThread().getThreadGroup(); } @Override public Thread newThread(Runnable runnable) { return new Thread(group, runnable, NAME_PREFIX + threadNumber.getAndIncrement()); } } interface EventListener { @Subscribe @AllowConcurrentEvents void onObject(Object o); } } 输出结果为： main:onObjectorderEvent-pool-1:onObject 最开始的时候，我们采用的是上面的方案，但慢慢的，我们有了新的要求，比如，灵活的控制同步和异步，guava的event bus控制同步异步需要两个event bus，一个普通的EventBus，一个AsyncEventBus，无法在同一个event bus中灵活控制同步和异步，还有一个问题就是，同步的情况下，无法给Listener排序，所以，在这种情况下，我们基于guava event bus的源码做了适合我们自己的改造，核心的类图如下： 核心流程为: 注册Listener时，EventBus通过SubscriberRegistry管理Event和Listener的关联关系，这个关联关系是通过解析传入的Listener类中含有@Subscriber注解的方法，这个注解有可能是加在Listener类的父类或者其实现的接口中的，会一直向上找，事件类型为方法入参，然后将所有信息汇总封装为Subscriber 发送Event时，EventBus通过SubscriberRegistry获取该Event或者该Event父类对应的所有Subscriber，然后传递到Dispatcher中，我们提供了OrderedDispatcher实现，该实现会通过Subscriber的order字段对其进行排序，然后依次调用Subscriber的process(event)方法，该方法会根据allowConcurrency和async等字段来决定方法怎么调用 如果执行的过程中出错，会通过SubscriberExceptionHandler来决定怎么处理 如果Event没有对应的Subscriber，封装为DeadEvent发送出去 整个流程和Guava EventBus是高度类似的，除了Dispatcher的实现以及Subscriber的同步、异步处理 示例代码如下： public class Main { public static final int AVAILABLE_PROCESSOR = Runtime.getRuntime().availableProcessors(); public static final int IO_THREAD_NUM = AVAILABLE_PROCESSOR * 2 + 1; public static final int CPU_THREAD_NUM = AVAILABLE_PROCESSOR + 1; public static final int DEFAULT_THREAD_POOL_WORK_QUEUE_SIZE = 1024; public static void main(String[] args) throws Exception { ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(IO_THREAD_NUM, IO_THREAD_NUM, 0, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(DEFAULT_THREAD_POOL_WORK_QUEUE_SIZE), new OrderEventHandlerThreadFactory()); EventBus eventBus = EventBus.builder().setIdentifier("test").setExecutor(threadPoolExecutor).build(); eventBus.register(new EventListener() { @Override public void onEvent1(Object event) { System.out.println(Thread.currentThread().getName() + ":onEvent1"); } @Override public void onEvent2(Object event) { System.out.println(Thread.currentThread().getName() + ":onEvent2"); } @Override public void onEventAsync(Object event) { System.out.println(Thread.currentThread().getName() + ":onEventAsync"); } }); eventBus.post(new Object()); threadPoolExecutor.shutdown(); } /** * 线程工厂，用于创建线程，主要为了方便线程命名 */ private static class OrderEventHandlerThreadFactory implements ThreadFactory { private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private static final String NAME_PREFIX = "orderEvent-pool-"; OrderEventHandlerThreadFactory() { SecurityManager sm = System.getSecurityManager(); group = sm != null ? sm.getThreadGroup() : Thread.currentThread().getThreadGroup(); } @Override public Thread newThread(Runnable runnable) { return new Thread(group, runnable, NAME_PREFIX + threadNumber.getAndIncrement()); } } public interface EventListener { @Subscribe(order = 2) void onEvent2(Object event); @Subscribe(order = 1) void onEvent1(Object event); @Subscribe(async = true) void onEventAsync(Object event); } } 输出结果为： main:onEvent1main:onEvent2orderEvent-pool-1:onEventAsync 对改造版EventBus代码感兴趣的可以去我的github中查看，地址为：EventBus 没有解决的问题：如何保证EventBus不丢事件，比如主逻辑执行完，事件发送之后，次要逻辑没有执行或执行了一部分发生宕机。目前在我们的系统中，次要逻辑都是一些短信、通知之类的，丢失也无所谓。]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>事件模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC中的一些锁以及核心AQS类]]></title>
    <url>%2F2018%2F06%2F04%2FJUC%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E9%94%81%E4%BB%A5%E5%8F%8A%E6%A0%B8%E5%BF%83AQS%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[已经研究完一段时间了，需要抽时间好好组织一下]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava限流器-RateLimiter]]></title>
    <url>%2F2018%2F05%2F26%2FGuava%E9%99%90%E6%B5%81%E5%99%A8-RateLimiter%2F</url>
    <content type="text"><![CDATA[最简单的限流思想最近在学习Guava使用的时候看到了RateLimiter，也就是限流器，其类的注释里面有提到最简单的限流思想如下： The simplest way to maintain a rate of QPS is to keep the timestamp of the last granted request, and ensure that (1/QPS) seconds have elapsed since then. For example, for a rate of QPS=5 (5 tokens per second), if we ensure that a request isn’t granted earlier than 200ms after the last one, then we achieve the intended rate. If a request comes and the last request was granted only 100ms ago, then we wait for another 100ms. At this rate, serving 15 fresh permits(i.e. for an acquire(15) request) naturally takes 3 seconds. 简单来说，就是我们可以通过记录最近一次被授权请求的请求时间，来达到限流的目的。比如说QPS为5（每秒允许通过5个请求），那么我们可以认为是两个请求之间需要间隔1/QPS秒，也就是200毫秒，通过判断当前请求时间和最近一次授权时间的时间间隔是否大于等于200毫秒来决定当前请求是否允许执行。当然，如果小于200ms我们也可以选择更新最新授权时间+等待，或者直接抛弃两种处理方式。 下面我们来看一下Guava里面到底是怎么实现的。 Guava中RateLimiter层次结构 常见用法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class RateLimiterTest &#123; public static void main(String[] args) throws Exception &#123; smoothBursty(); smoothWarmingUp(); &#125; public static void smoothBursty() throws Exception &#123; System.out.println("-----------------SmoothBursty-----------------"); RateLimiter rateLimter = RateLimiter.create(1); Stopwatch started = Stopwatch.createStarted(); rateLimter.acquire(); System.out.println("A1:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.MILLISECONDS.sleep(300); rateLimter.acquire(); System.out.println("A2:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.SECONDS.sleep(6); rateLimter.acquire(5); System.out.println("A3:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.MILLISECONDS.sleep(1500); rateLimter.acquire(); System.out.println("A4:" + started.elapsed(TimeUnit.SECONDS)); System.out.println("-----------------SmoothBursty-----------------"); &#125; public static void smoothWarmingUp() throws Exception &#123; System.out.println("-----------------SmoothWarmingUp-----------------"); RateLimiter rateLimter = RateLimiter.create(1, 3, TimeUnit.SECONDS); Stopwatch started = Stopwatch.createStarted(); rateLimter.acquire(); System.out.println("A1:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A2:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A3:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A4:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A5:" + started.elapsed(TimeUnit.MILLISECONDS)); TimeUnit.SECONDS.sleep(5); rateLimter.acquire(); System.out.println("A6:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A7:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A8:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A9:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A10:" + started.elapsed(TimeUnit.MILLISECONDS)); System.out.println("-----------------SmoothWarmingUp-----------------"); &#125;&#125; 上面的代码没什么实际业务场景，仅仅是为了验证一些东西。 SmoothBurstySmoothBursty翻译成中文，是平稳和突发，意思就是这个限流器可以平稳限流，也可以应对突发的大量请求。 SmoothBursty的一些关键点 令牌法 采用令牌算法来进行限流，速率不固定 囤积令牌 默认最多囤积一秒的令牌数 下一次可通行时间点 记录下一次开始发放令牌的时间点 前人挖坑，后人埋 如果当前请求时间大于记录的下一次可用时间点，不管请求多少令牌，直接放过，根据请求的令牌数以及当前囤积的令牌数来将“下一次可用时间点”往后推；如果当前求情时间小于记录的下一次可用时间点，则wait一段时间（这段时间=下一次可用时间点 - 当前请求时间），然后将下一次可用时间点往后推，推后的时长 = 当前请求令牌数 * 生成一个令牌需要的时间 SmoothBursty中的一些名词解释 maxBurstSeconds 可以理解为RateLimiter未被使用时，可以囤积多少秒的令牌，Guava默认为1且没有提供修改方法 storedPermits 当前囤积的令牌数 maxPermits 最大可囤积令牌数 stableIntervalMicros 每生成一个令牌的时间间隔，比如QPS为5，那么每200ms生成一个令牌 nextFreeTicketMicros 可以理解为下次产生可用令牌的时间，这个时间每次acquire的时候都会更新，只能是一个将来的时间点 stopwatch 可以理解为一个计时器，在RateLimiter被创建的时候开始计时 mutexDoNotUseDirectly 锁对象 简单工作原理图如上图所示，横向的矩形框表示时间，假设QPS为1，每一格为1秒,上面的箭头表示下次允许请求通过的时间点（nextFreeTicketMicros），下面的箭头表示每次请求，针对每次请求做分析（只针对acquire，不包含tryAcquire）： A1，请求1个令牌，此时限流器刚启动，nextFreeTicketMicros为N0，接收到A1请求后，允许请求通过，当前没有令牌可用，所以透支一个，nextFreeTicketMicros会被推到N1（因为生成一个令牌需要1秒） A2，请求1个令牌，由于nextFreeTicketMicros为N1，所以该请求需要wait一段时间，这段时间等于图中A2到N1的黄色部分，然后生成A2所需要的令牌又需要1秒钟，所以nextFreeTicketMicros会被推到N2 A3，请求5个令牌，由于N2到N7没有请求产生，所以到了A3请求时，会有一个令牌囤积（QPS为1，SmoothBursty默认囤积1秒产生的令牌），然后nextFreeTicketMicros首先会被推到N7，由于A3请求5个令牌，用掉囤积的一个后，还需要透支4个，所以nextFreeTicketMicros又会被推到N11，A3请求通过 A4，请求1个令牌，由于nextFreeTicketMicros为N11，所以A4请求需要wait一段时间，这段时间等于图中A4到N11的黄色部分，生成A4所需要的令牌需要1秒，所以nextFreeTicketMicros会被推到N12 下面的代码可以用来验证上面的流程： 1234567891011121314151617public class RateLimiterTest &#123; public static void main(String[] args) throws Exception &#123; RateLimiter rateLimter = RateLimiter.create(1); Stopwatch started = Stopwatch.createStarted(); rateLimter.acquire(); System.out.println("A1:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.MILLISECONDS.sleep(300); rateLimter.acquire(); System.out.println("A2:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.SECONDS.sleep(6); rateLimter.acquire(5); System.out.println("A3:" + started.elapsed(TimeUnit.SECONDS)); TimeUnit.MILLISECONDS.sleep(1500); rateLimter.acquire(); System.out.println("A4:" + started.elapsed(TimeUnit.SECONDS)); &#125;&#125; 打印结果为： A1:0A2:1A3:7A4:11 分别代表A1请求在第0秒通过，A2在第1秒通过，A3在第7秒通过，A4在第11秒通过 至于tryAcquire，就是判断当前请求时间是否 &gt;= nextFreeTicketMicros - timeout，如果成立，走类似acquire的逻辑，返回true；如果当前请求时间加上timeout时长还达不到nextFreeTicketMicros，直接返回false 关键方法源码关键代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public double acquire(int permits) &#123; //获得所需令牌要wait多久 long microsToWait = reserve(permits); //sleep stopwatch.sleepMicrosUninterruptibly(microsToWait); return 1.0 * microsToWait / SECONDS.toMicros(1L);&#125;final long reserve(int permits) &#123; //校验permits必须大于0 checkPermits(permits); synchronized (mutex()) &#123; return reserveAndGetWaitLength(permits, stopwatch.readMicros()); &#125;&#125;final long reserveAndGetWaitLength(int permits, long nowMicros) &#123; //获得令牌可用时刻 long momentAvailable = reserveEarliestAvailable(permits, nowMicros); //通过令牌可用时刻 - 当前请求时刻来决定当前请求是否需要sleep return max(momentAvailable - nowMicros, 0);&#125;/** * 核心方法 */final long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123; resync(nowMicros); long returnValue = nextFreeTicketMicros; //本次请求消耗多少囤积的令牌 double storedPermitsToSpend = min(requiredPermits, this.storedPermits); //本次请求需要新生成多少令牌 double freshPermits = requiredPermits - storedPermitsToSpend; //对于SmoothBursty来说，计算生成freshPermits个令牌需要多久 long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); //将nextFreeTicketMicros向后推，推后的时间等于生成freshPermits个令牌所需要的时间 this.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros); //扣减消耗的囤积令牌 this.storedPermits -= storedPermitsToSpend; //返回的是当前请求来临时的nextFreeTicketMicros return returnValue;&#125;void resync(long nowMicros) &#123; /* * 如果当前请求时间大于nextFreeTicketMicros，计算囤积令牌并将nextFreeTicketMicros设置为当前请求时间 * nextFreeTicketMicros只能是现在或者将来，如果是一个过去的时间，会被同步为现在 */ if (nowMicros &gt; nextFreeTicketMicros) &#123; double newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros(); storedPermits = min(maxPermits, storedPermits + newPermits); nextFreeTicketMicros = nowMicros; &#125;&#125;public boolean tryAcquire(int permits, long timeout, TimeUnit unit) &#123; long timeoutMicros = max(unit.toMicros(timeout), 0); checkPermits(permits); long microsToWait; synchronized (mutex()) &#123; long nowMicros = stopwatch.readMicros(); if (!canAcquire(nowMicros, timeoutMicros)) &#123; return false; &#125; else &#123; microsToWait = reserveAndGetWaitLength(permits, nowMicros); &#125; &#125; stopwatch.sleepMicrosUninterruptibly(microsToWait); return true;&#125;private boolean canAcquire(long nowMicros, long timeoutMicros) &#123; //queryEarliestAvailable(nowMicros) = nextFreeTicketMicros return queryEarliestAvailable(nowMicros) - timeoutMicros &lt;= nowMicros;&#125; SmoothWarmingUp与SmoothBursty的主要区别 漏斗法 采用漏斗法限流，会有预热阶段，预热阶段的QPS要小于预期值，稳定阶段QPS等于预期值 storedPermits和maxPermits的含义改变，storedPermits的含义更多的是有多久没有访问过限流器，用来计算预热时间，maxPermits还是其边界值 花费storedPermits也会将nextFreeTicketMicros往后推 RateLimiter空闲时，令牌的生成间隔不是stableIntervalMicros，而是maxPermits / warmupPeriod，所以，从0填满storedPermits耗时为warmupPeriod 工作原理可以通过官方的一段javadoc来了解SmoothWarmingUp的工作原理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * This implements the following function where coldInterval = coldFactor * stableInterval. * * &lt;pre&gt; * ^ throttling * | * cold + / * interval | /. * | / . * | / . ← "warmup period" is the area of the trapezoid between * | / . thresholdPermits and maxPermits * | / . * | / . * | / . * stable +----------/ WARM . * interval | . UP . * | . PERIOD. * | . . * 0 +----------+-------+--------------→ storedPermits * 0 thresholdPermits maxPermits * &lt;/pre&gt; * * Before going into the details of this particular function, let's keep in mind the basics: * * &lt;ol&gt; * &lt;li&gt;The state of the RateLimiter (storedPermits) is a vertical line in this figure. * &lt;li&gt;When the RateLimiter is not used, this goes right (up to maxPermits) * &lt;li&gt;When the RateLimiter is used, this goes left (down to zero), since if we have * storedPermits, we serve from those first * &lt;li&gt;When _unused_, we go right at a constant rate! The rate at which we move to the right is * chosen as maxPermits / warmupPeriod. This ensures that the time it takes to go from 0 to * maxPermits is equal to warmupPeriod. * &lt;li&gt;When _used_, the time it takes, as explained in the introductory class note, is equal to * the integral of our function, between X permits and X-K permits, assuming we want to * spend K saved permits. * &lt;/ol&gt; * * &lt;p&gt;In summary, the time it takes to move to the left (spend K permits), is equal to the area of * the function of width == K. * * &lt;p&gt;Assuming we have saturated demand, the time to go from maxPermits to thresholdPermits is * equal to warmupPeriod. And the time to go from thresholdPermits to 0 is warmupPeriod/2. (The * reason that this is warmupPeriod/2 is to maintain the behavior of the original implementation * where coldFactor was hard coded as 3.) * * &lt;p&gt;It remains to calculate thresholdsPermits and maxPermits. * * &lt;ul&gt; * &lt;li&gt;The time to go from thresholdPermits to 0 is equal to the integral of the function * between 0 and thresholdPermits. This is thresholdPermits * stableIntervals. By (5) it is * also equal to warmupPeriod/2. Therefore * &lt;blockquote&gt; * thresholdPermits = 0.5 * warmupPeriod / stableInterval * &lt;/blockquote&gt; * &lt;li&gt;The time to go from maxPermits to thresholdPermits is equal to the integral of the * function between thresholdPermits and maxPermits. This is the area of the pictured * trapezoid, and it is equal to 0.5 * (stableInterval + coldInterval) * (maxPermits - * thresholdPermits). It is also equal to warmupPeriod, so * &lt;blockquote&gt; * maxPermits = thresholdPermits + 2 * warmupPeriod / (stableInterval + coldInterval) * &lt;/blockquote&gt; * &lt;/ul&gt; */ 简单流程验证代码： 1234567891011121314151617181920212223242526272829public class RateLimiterTest &#123; public static void main(String[] args) throws Exception &#123; RateLimiter rateLimter = RateLimiter.create(1, 3, TimeUnit.SECONDS); Stopwatch started = Stopwatch.createStarted(); rateLimter.acquire(); System.out.println("A1:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A2:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A3:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A4:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A5:" + started.elapsed(TimeUnit.MILLISECONDS)); TimeUnit.SECONDS.sleep(5); rateLimter.acquire(); System.out.println("A6:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A7:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A8:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A9:" + started.elapsed(TimeUnit.MILLISECONDS)); rateLimter.acquire(); System.out.println("A10:" + started.elapsed(TimeUnit.MILLISECONDS)); &#125; &#125; 输出结果: A1:1A2:2338A3:3500A4:4504A5:5500A6:10501A7:12835A8:14002A9:15006A10:16004 可以看到，请求A1和A2间隔为2000多毫秒，A2和A3间隔1160毫秒左右，A3、A4、A5之间间隔基本为1000毫秒，然后sleep一段时间后，发现A6/7/8/9/10之间的间隔和A1/2/3/4/5类似 关键方法源码扩展阅读常见的限流算法 计数法 滑动窗口 漏斗法 令牌法]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>限流器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PropertyDescriptor使用时遇到的坑]]></title>
    <url>%2F2018%2F05%2F25%2FPropertyDescriptor%E4%BD%BF%E7%94%A8%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[有一段时间特别喜欢链式编程，然后把自己的IDEA中自动生成getters and setters的setters模板设置成了Builder模式，生成的代码如下： 12345678910111213public class Person &#123; privat String name; public String getName() &#123; return this.name; &#125; public Person setName(String name) &#123; this.name = name; return this; &#125; &#125; 相信有不少人也喜欢这么写，这样写起来比单独再写一个Builder要简单很多，但是在最近遇到一个问题，就是在使用PropertyDescriptor的时候，会遇到java.beans.IntrospectionException: Method not found: setName的问题，依稀这段代码在很久以前使用的时候还是没有问题的，为了查明问题，翻阅了PropertyDescriptor的源码，发现在JDK1.7以及1.7之后，PropertyDescriptor类的getWriteMethod方法发成了改变，具体如下： 红框部分代码，是在1.7以及1.7以后新加入的，对set方法的返回值做了约束，返回值必须为void。 JDK为什么要这么改？个人猜想有两点，一是JavaBean规范，再一个可能是因为Java中的方法特征签名和字节码层面的方法特征签名不一致的问题，在Java语言中，方法的特征签名包括方法名、参数顺序以及参数类型，在字节码层面，方法签名特征还多了返回值以及受检查异常列表。所以，为了更好的兼容性，还是老老实实写完整的Builder模式吧。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
